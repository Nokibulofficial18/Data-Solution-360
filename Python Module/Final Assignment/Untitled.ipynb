{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTqRTeZCAdMm",
        "outputId": "424ce7f2-2c03-4143-ef11-df65c0d332ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# ðŸ“Œ Step 1: Mount Google Drive\n",
        "# ===============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change this path to your ZIP dataset in Drive\n",
        "zip_path = \"/content/drive/Shareddrives/Eye Dataset (Mahin)/Datasets/Drive Dataset/DriveDataset.zip\"\n",
        "\n",
        "# ===============================\n",
        "# ðŸ“Œ Step 2: Unzip Dataset\n",
        "# ===============================\n",
        "!unzip -qo \"$zip_path\" -d /content/mydb\n",
        "\n",
        "#dataset_path = \"/content/dataset\"  # extracted folder\n",
        "train_path = \"/content/mydb/DRIVE/test/images\"\n",
        "test_path = \"/content/mydb/DRIVE/training/images\""
      ],
      "metadata": {
        "id": "zK3EbAF-GvaP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Install required libraries\n",
        "!pip install python-docx opencv-python-headless\n",
        "\n",
        "# âœ… Imports\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from docx import Document\n",
        "from docx.shared import Inches\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "\n",
        "# âœ… Initialize Word document\n",
        "doc = Document()\n",
        "doc.add_heading(\"DRIVE Eye Fundus Dataset Analysis\", 0)\n",
        "\n",
        "# âœ… Analyze images in a folder\n",
        "def analyze_folder(folder_path, section_name):\n",
        "    doc.add_heading(section_name, level=1)\n",
        "    image_files = sorted([f for f in os.listdir(folder_path) if f.endswith(('.tif', '.jpg', '.png'))])\n",
        "    doc.add_paragraph(f\"Total images in {section_name}: {len(image_files)}\")\n",
        "\n",
        "    sizes = []\n",
        "    channels = []\n",
        "\n",
        "    for i, image_file in enumerate(image_files[:5]):\n",
        "        img_path = os.path.join(folder_path, image_file)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        h, w, c = img.shape\n",
        "        sizes.append((h, w))\n",
        "        channels.append(c)\n",
        "\n",
        "        # Save and insert preview image\n",
        "        preview_path = f\"/content/sample_{section_name.replace(' ', '_')}_{i}.jpg\"\n",
        "        cv2.imwrite(preview_path, img)\n",
        "        doc.add_paragraph(f\"Sample Image {i+1}: {image_file} - Size: {h}x{w}, Channels: {c}\")\n",
        "        doc.add_picture(preview_path, width=Inches(3.5))\n",
        "\n",
        "    return image_files, sizes, channels\n",
        "\n",
        "# âœ… Plot image size distribution\n",
        "def plot_size_distribution(sizes, label):\n",
        "    size_labels = [f\"{h}x{w}\" for h, w in sizes]\n",
        "    size_counts = pd.Series(size_labels).value_counts()\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    sns.barplot(x=size_counts.index, y=size_counts.values, palette=\"viridis\")\n",
        "    plt.title(f\"{label} - Image Size Distribution\")\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    chart_path = f\"/content/{label.lower().replace(' ', '_')}_sizes.png\"\n",
        "    plt.savefig(chart_path)\n",
        "    doc.add_picture(chart_path, width=Inches(5))\n",
        "    plt.close()\n",
        "\n",
        "# âœ… Plot pixel intensity histogram\n",
        "def plot_intensity_histogram(folder_path, label):\n",
        "    pixel_values = []\n",
        "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.png', '.tif'))]\n",
        "    for f in image_files[:10]:  # Limit to 10 images\n",
        "        img = cv2.imread(os.path.join(folder_path, f))\n",
        "        if img is None: continue\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        pixel_values.extend(gray.flatten())\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    plt.hist(pixel_values, bins=50, color='skyblue')\n",
        "    plt.title(f\"{label} - Pixel Intensity Histogram\")\n",
        "    plt.xlabel(\"Pixel Value\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    hist_path = f\"/content/{label.lower().replace(' ', '_')}_histogram.png\"\n",
        "    plt.savefig(hist_path)\n",
        "    doc.add_picture(hist_path, width=Inches(5))\n",
        "    plt.close()\n",
        "\n",
        "# âœ… Analyze Training Set\n",
        "train_files, train_sizes, train_channels = analyze_folder(train_path, \"Training Set\")\n",
        "\n",
        "# âœ… Analyze Test Set\n",
        "test_files, test_sizes, test_channels = analyze_folder(test_path, \"Test Set\")\n",
        "\n",
        "# âœ… Add Summary\n",
        "doc.add_heading(\"Summary\", level=1)\n",
        "doc.add_paragraph(f\"Total Training Images: {len(train_files)}\")\n",
        "doc.add_paragraph(f\"Total Test Images: {len(test_files)}\")\n",
        "doc.add_paragraph(f\"Unique Training Image Sizes: {list(set(train_sizes))}\")\n",
        "doc.add_paragraph(f\"Unique Test Image Sizes: {list(set(test_sizes))}\")\n",
        "doc.add_paragraph(f\"Training Image Channels: {list(set(train_channels))}\")\n",
        "doc.add_paragraph(f\"Test Image Channels: {list(set(test_channels))}\")\n",
        "\n",
        "# âœ… Add Charts\n",
        "plot_size_distribution(train_sizes, \"Training Set\")\n",
        "plot_size_distribution(test_sizes, \"Test Set\")\n",
        "plot_intensity_histogram(train_path, \"Training Set\")\n",
        "plot_intensity_histogram(test_path, \"Test Set\")\n",
        "\n",
        "# âœ… Save DOCX Report\n",
        "report_path = \"/content/drive_dataset_analysis.docx\"\n",
        "doc.save(report_path)\n",
        "print(f\"âœ… Word report saved to: {report_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92xuweeER1eT",
        "outputId": "8e649635-dc58-484a-b7e0-20a4f8660bd7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.2.0)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.14.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (2.0.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4258087514.py:52: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=size_counts.index, y=size_counts.values, palette=\"viridis\")\n",
            "/tmp/ipython-input-4258087514.py:52: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=size_counts.index, y=size_counts.values, palette=\"viridis\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Word report saved to: /content/drive_dataset_analysis.docx\n"
          ]
        }
      ]
    }
  ]
}